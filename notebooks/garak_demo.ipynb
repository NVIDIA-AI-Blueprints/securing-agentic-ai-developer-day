{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc42996-d612-4eb8-a40c-a46fbd4e6925",
   "metadata": {},
   "source": [
    "![NVIDIA Header](assets/header.png)\n",
    "\n",
    "# **Securing Agentic AI Developer Day: Garak Demo**\n",
    "\n",
    "`garak` is a tool for evaluating weaknesses in large language models (LLMs) and LLM-based systems. As AI systems become more complex, securing them against potential attacks become critical. Garak helps identify weaknesses that could be exploited in these models or systems, providing insights into potential security flaws before and after deployment.\n",
    "\n",
    "In this demo, we will explore how `garak` can be applied to an LLM directly. Our goal is to demonstrate how you can leverage `garak` to analyze potential security vulnerabilities in AI agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e98292",
   "metadata": {},
   "source": [
    "## Notebook Contents\n",
    "\n",
    "- [Securing Agentic AI Developer Day: Garak Demo](#securing-agentic-ai-developer-day-garak-demo)\n",
    "- [Fetch API Key](#fetch-api-key)\n",
    "- [Generators and Probes](#generators-and-probes)\n",
    "  - [Generators](#generators)\n",
    "  - [Probes](#probes)\n",
    "- [Creating a test](#creating-a-test)\n",
    "  - [Choosing a Generator](#choosing-a-generator)\n",
    "  - [Choosing a Probe](#choosing-a-probe)\n",
    "  - [Running a Test Probe](#running-a-test-probe)\n",
    "- [Configs: Setting Up Your Environment](#configs-setting-up-your-environment)\n",
    "  - [Breaking it Down](#breaking-it-down)\n",
    "- [Evaluating `garak` Results](#evaluating-garak-results)\n",
    "- [Conclusion](#conclusion)\n",
    "- [References](#references)\n",
    "\n",
    "## Fetch API Key \n",
    "Run the following cell block to fetch the API Key in the setup phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4dd3a",
   "metadata": {},
   "source": [
    "## Generators and Probes\n",
    "The power of `garak` comes from the combination of generators, probes and detectors. The **probe** produces the inputs data and the **generator** obtains a reaction from the target and the **probe** evaluates the target's reaction to that data. This collaboration allows you to identify weakness such as how the model might fail under adversarial or stressful conditions. They allow us to comprehensively test the security and robustness of the model.\n",
    "\n",
    "### Generators\n",
    "A **generator** is a tool that accepts specific inputs or data that are fed into the model. These inputs can range from typical usage scenarios to adversarial examples designed to challenge the model's behavior. By using the right generator, we can test how the model responds to a variety of input conditions.\n",
    "\n",
    "To view all of the available generators in `garak` we use the `--list_generators` flag. This command will display all of the available generators that you can use to test a model.\n",
    "\n",
    "Run the following command to see all of the available generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2796e59-309a-44f5-a6a3-981549e82ac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! garak --list_generators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a821645b",
   "metadata": {},
   "source": [
    "### Probes\n",
    "A **probe** is a predefined test designed to evaluate how the model responds to inputs created by the generators. Probes are used to simulate various types of attacks or tests to identify weakneesses in the model.  Probes and are paired with detectors flag indicators of weakness from the generator reaction to inputs provided by the probe.\n",
    "\n",
    "To view all of the available probes in `garak` we use the `--list_probes` flag. This command will display all of the available probes that you can use to test a model.\n",
    "\n",
    "Run the following command to see all of the available probes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369642ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "! garak --list_probes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625c10a-ea1a-47b6-83aa-b32df5fde851",
   "metadata": {},
   "source": [
    "## Creating a test\n",
    "\n",
    "Based on the list of probes and generators, select a pair that suits the security issue that you want to test.\n",
    "\n",
    "## Choosing a Generator\n",
    "\n",
    "Based on the list of generators, select a generator that matches the execution stack you want to test.\n",
    "\n",
    "For this demo, we will use `garak.generators.nim`, a pre-configured generator from the list of generators available in `garak`.\n",
    "- Target Model: `meta/llama-3.3-70b-instruct`\n",
    "- Generator: `nim`\n",
    "\n",
    "\n",
    "To specify this model and generator in `garak`, we'll need the following flags:\n",
    "```\n",
    "garak --model_name meta/llama-3.3-70b-instruct --model_type nim\n",
    "```\n",
    "\n",
    "## Choosing a Probe\n",
    "`garak` includes a wide range of probes. You can either choose to run specific probes to evaluate targeted weaknesses or run a broad scan to uncover general weaknesses.\n",
    "\n",
    "If you run `garak` without specifying a probe, it will execute a **default** scan. This scan runs a comprehensive set of probes to evaluate the model's security across multiple dimensions. This is a quick way to get a broad understanding of how the model behaves under different conditions.\n",
    "\n",
    "If you want to focus on a specific area or weakness, you can select individual probes by using the `-p` flag followed by one or two probe names. This allows you to be more precise in your testing and focus on particular aspects of the model.\n",
    "\n",
    "### Running a Test Probe\n",
    "\n",
    "Let's try running a simple test probe to see how the model handles a basic security check. Use the following command to execute a quick scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617fbd0-8446-4f92-895c-382b9e419003",
   "metadata": {},
   "outputs": [],
   "source": [
    "! garak --model_name meta/llama-3.3-70b-instruct --model_type nim --probes test.Test --generations 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db03b5-0209-4e9b-bae1-4fab18ed3442",
   "metadata": {},
   "source": [
    "## Configs: Setting Up Your Envionment\n",
    "\n",
    "If we are running a large number of probes or need to specify additional generator arguments, we can use a config file.\n",
    "\n",
    "These config files are written in YAML format and help streamline the CLI invocation. While using a config file is more simpler, all of the same options can still be passed via the CLI if preferred.\n",
    "\n",
    "Here is an example config:\n",
    "\n",
    "```\n",
    "---\n",
    "system:\n",
    "  parallel_attempts: 2\n",
    "\n",
    "run:\n",
    "  generations: 3\n",
    "\n",
    "plugins:\n",
    "  probe_spec: xss.MarkdownImageExfil,suffix.GCGCached,dan.DanInTheWildMini,latentinjection.LatentInjectionResume\n",
    "  extended_detectors: false\n",
    "  probes:\n",
    "    encoding:\n",
    "      payloads:\n",
    "        - default\n",
    "        - xss\n",
    "  model_type: nim\n",
    "  model_name: meta/llama-3.3-70b-instruct\n",
    "\n",
    "reporting:\n",
    "  report_prefix: guardrails_demo\n",
    "```\n",
    "\n",
    "### Breaking it Down\n",
    "\n",
    "```\n",
    "system:\n",
    "  parallel_attempts: 2\n",
    "```\n",
    "This will parallelize our attempts (running 2 at once) to speed up the process -- since thousands of attempts are made, this can reduce run time by quite a bit, but needs to be balanced with our available compute and memory capacity.\n",
    "\n",
    "```\n",
    "run:\n",
    "  generations: 3\n",
    "```\n",
    "Since LLMs generally will not produce the exact same output given the same input at each generation, we typically want multiple generations so we can average out the behavior.\n",
    "Setting `generations` to 1 will be faster but provide a less full picture of behavior, setting `generations` very high will provide a fuller picture of a model's typical behavior, but will take longer.\n",
    "\n",
    "```\n",
    "plugins:\n",
    "```\n",
    "The plugins heading handles all `plugins` -- generators, probes, buffs, and detectors.\n",
    "\n",
    "```\n",
    "  probe_spec: xss.MarkdownImageExfil,suffix.GCGCached,dan.DanInTheWildMini,latentinjection.LatentInjectionResume\n",
    "  extended_detectors: false\n",
    "```\n",
    "The probes that we choose here are all categories that can expose potential security risks in agentic systems.\n",
    "* `xss.MarkdownImageExfil` tells us about potential risks related to [cross site scripting](https://owasp.org/www-community/attacks/xss/)\n",
    "* `suffix.GCGCached` is an adversarial suffix attack\n",
    "* `dan.DanInTheWildMini` is a selection of known jailbreak prompts that have been effective in the wild\n",
    "* The `latentinjection` probe looks at potential prompt injection risks associated with third party data.\n",
    "By setting `extended_detectors: false`, we reduce the overhead of our detectors, running only the primary detectors for each probe.\n",
    "\n",
    "```\n",
    "  model_type: nim\n",
    "  model_name: meta/llama-3.3-70b-instruct\n",
    "```\n",
    "Here, we specify that we're using the `nim` generator with the `meta/llama-3.3-70b-instruct` model.\n",
    "If we want to specify additional parameters, we can do so under the `generators/nim` part of the YAML file.\n",
    "\n",
    "In some cases, like with `huggingface` generators, we will want to specify, for example, that `trust_remote_code` should be `True`, but can specify other things like to use `fp16` or `bf16`, `max_tokens`, or any other parameter the generator accepts.\n",
    "\n",
    "```\n",
    "reporting:\n",
    "  report_prefix: garak_demo\n",
    "```\n",
    "This part of the config tells us to prefix the report with the string `garak_demo` instead of the run ID, making it easier to find our outputs.\n",
    "\n",
    "This config is saved locally under `demo.conf`, so let's run it by passing the config to `garak` via the `--config` CLI argument.\n",
    "\n",
    "**NOTE**: garak runs can take a while! Feel free to peruse the [garak user guide](https://docs.garak.ai/garak) or look at the [probe docs](https://reference.garak.ai/en/latest/probes.html) while you wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ba7eb-9c41-4c6b-b022-acbbfe1c62c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!garak --config demo.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c61246e-e112-4ca5-9545-3109ac187a5a",
   "metadata": {},
   "source": [
    "## Evaluating `garak` Results\n",
    "After running your selected generators and probes with `garak` it's time to evaluate the results. The feedback you receive will provide insights into the security and performance of the model.\n",
    "\n",
    "The raw data for all probes and evaluations is in the `report.jsonl` file -- a JSON lines file containing all of the prompts, responses, and detector results for your run.\n",
    "\n",
    "This is aggregated in a reader-friendly format in the `report.html` file.\n",
    "\n",
    "`garak` uses the [XDG Base Directory](https://specifications.freedesktop.org/basedir-spec/latest/) specification. Here is where results will be located depending on your OS:\n",
    "- **Linux**:  `/home/{your_username}/.local/share/garak/garak_runs/`.\n",
    "- **MacOS** `/Users/{your_username}/.local/share/garak/garak_runs`.\n",
    "- **Windows** `%USERPROFILE%/.local/share/garak/garak_runs`.\n",
    "\n",
    "If you are running locally, you can copy the report over or simply point your browser to the location on disk. \n",
    "If you've kept the report prefix and are running on Linux, that should be `/home/{your_username}/.local/share/garak/garak_runs/garak_demo.report.html`. \n",
    "If you are on another operating system, swap out the XDG base directory as appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93adedae-c2c9-474b-b74c-5fd564993e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /root/.local/share/garak/garak_runs/garak_demo.report.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1082155a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we explored Garak, a tool for assessing the security of large language models (LLMs) and AI systems. By using probes and generators, we demonstrated how Garak helps identify weaknesses such as adversarial inputs, prompt injections, and performance issues.\n",
    "\n",
    "For agentic AI workflows, this is especially important, as these systems must operate securely and predictably in dynamic environments. Garak allows us to proactively test these models, ensuring they can handle unexpected inputs and perform safely within defined boundaries.\n",
    "\n",
    "By integrating Garak into agentic AI development, we can create more resilient, secure systems that minimize risk and maintain trust, laying the groundwork for reliable and safe AI-driven workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d612322c",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [Garak GitHub Repository](https://github.com/NVIDIA/garak): The official repository for Garak, containing the source code, examples, and documentation.\n",
    "\n",
    "2. [Garak Documentation](https://github.com/NVIDIA/garak/blob/main/README.md): Detailed documentation on how to use Garak, including setup, probes, and generators.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
